{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70361a4e-1257-4b09-819a-52d37a7f6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86102e3f-f685-4caf-944d-46c7ce02ca03",
   "metadata": {},
   "source": [
    "# Project 3A:Read file, Tokenize, Count Words, Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da206f73-3a0e-45a3-a6b5-e636930b9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "MR = \"the_masque_of_the_red_death.txt\"\n",
    "UL = \"ulysses.txt\"\n",
    "YT = \"yeats.txt\"\n",
    "MM = \"middlemarch.txt\"\n",
    "\n",
    "fin = UL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6145303-ac8a-404a-9ab7-95d2f78f43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully\n"
     ]
    }
   ],
   "source": [
    "#Read in Data\n",
    "#I didn't ask students to do this\n",
    "try:\n",
    "    with open(fin, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    print(\"File read successfully\")\n",
    "except Exception:\n",
    "    print(\"File read error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7fb5af-a135-4ca2-86b5-684be2440c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokenized\n"
     ]
    }
   ],
   "source": [
    "#Tokenize\n",
    "string = re.sub('\\n',' ', text)\n",
    "\n",
    "#create a list containing all lower case characters\n",
    "good_chars = [chr(value) for value in range(ord('a'),ord('z') + 1,1)]\n",
    "good_chars.append(' ') #spaces are good characters\n",
    "string = string.lower()\n",
    "\n",
    "new_str = ''\n",
    "for ch in string:\n",
    "   if ch in good_chars:\n",
    "      new_str = new_str + ch\n",
    "       \n",
    "#make list of words by removing spaces\n",
    "lst = new_str.split()\n",
    "\n",
    "print(\"Input tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f092712-44d5-4a46-9a15-1a677938c27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words counted\n"
     ]
    }
   ],
   "source": [
    "#Count Words\n",
    "\n",
    "count_dict = {}\n",
    "for word in lst:\n",
    "   if word in count_dict:\n",
    "      count_dict[word] = count_dict[word] + 1\n",
    "   else:\n",
    "      count_dict[word] = 1\n",
    "       \n",
    "#A failed attempt at elegance  \n",
    "#cnt_dict = {word:lst.count(word) for word in lst}\n",
    "print(\"Words counted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9611fb5c-5752-43ae-a0b9-f37f048a567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully written\n"
     ]
    }
   ],
   "source": [
    "#Build dataframe and write CSV file\n",
    "\n",
    "#Make an iterable object from the dictiobary tuples\n",
    "lst = count_dict.items()\n",
    "\n",
    "#Reverse the tuple info from (word,freq) to (freq,word)\n",
    "freq_word_lst = [(item[1],item[0]) for item in lst]\n",
    "\n",
    "df = pd.DataFrame(freq_word_lst, columns=['freq','word'])\n",
    "\n",
    "#I didn't ask students to do this\n",
    "try:\n",
    "    df.to_csv(\"data.csv\", index=False)\n",
    "    print(\"CSV file successfully written\")\n",
    "except Exception:\n",
    "    print(\"File write error\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd62759-5382-428c-8179-18177c10b27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5d1b9-a17a-48d4-8a21-dfc924949ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3befe1-ffcf-4c81-b525-dec7f53020ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f743b-67dc-45ca-b624-2a4f84ba7891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44acba8a-555b-4f91-8fb3-b91b39ebbeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2decc72-167f-4d0b-960b-387afe0056aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fe4c5-826b-4db6-acda-e4c634716b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181b9a9-cca1-42d4-b974-82622005e678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5e695-8eaa-4d28-a955-1e88736ecd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24b0aa-55bd-467a-a474-ccb64fb98919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe76fec-c169-402e-a6cd-2cba984a3a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
